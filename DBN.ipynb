{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This implementation utilizes PyTorch to construct the Deep Belief Network(DBN) model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.4.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install torch numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.4.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# in case torch is not installed\n",
    "%pip install torch scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# in case pandas was not installed\n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# in case matplotlib was not installed\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from tqdm) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-4.0.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.13.2-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from optuna) (2.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from optuna) (24.1)\n",
      "Collecting sqlalchemy>=1.3.0 (from optuna)\n",
      "  Downloading SQLAlchemy-2.0.32-cp310-cp310-win_amd64.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from optuna) (4.66.5)\n",
      "Collecting PyYAML (from optuna)\n",
      "  Downloading PyYAML-6.0.2-cp310-cp310-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy>=1.3.0->optuna)\n",
      "  Downloading greenlet-3.0.3-cp310-cp310-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
      "Downloading optuna-4.0.0-py3-none-any.whl (362 kB)\n",
      "Downloading alembic-1.13.2-py3-none-any.whl (232 kB)\n",
      "Downloading SQLAlchemy-2.0.32-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.1 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.1 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.1 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.1 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.5/2.1 MB 364.6 kB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 0.5/2.1 MB 364.6 kB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 0.5/2.1 MB 364.6 kB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 0.5/2.1 MB 364.6 kB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 0.5/2.1 MB 364.6 kB/s eta 0:00:05\n",
      "   --------------- ------------------------ 0.8/2.1 MB 296.9 kB/s eta 0:00:05\n",
      "   --------------- ------------------------ 0.8/2.1 MB 296.9 kB/s eta 0:00:05\n",
      "   --------------- ------------------------ 0.8/2.1 MB 296.9 kB/s eta 0:00:05\n",
      "   --------------- ------------------------ 0.8/2.1 MB 296.9 kB/s eta 0:00:05\n",
      "   --------------- ------------------------ 0.8/2.1 MB 296.9 kB/s eta 0:00:05\n",
      "   --------------- ------------------------ 0.8/2.1 MB 296.9 kB/s eta 0:00:05\n",
      "   -------------------- ------------------- 1.0/2.1 MB 249.2 kB/s eta 0:00:05\n",
      "   -------------------- ------------------- 1.0/2.1 MB 249.2 kB/s eta 0:00:05\n",
      "   -------------------- ------------------- 1.0/2.1 MB 249.2 kB/s eta 0:00:05\n",
      "   ------------------------- -------------- 1.3/2.1 MB 277.3 kB/s eta 0:00:03\n",
      "   ------------------------- -------------- 1.3/2.1 MB 277.3 kB/s eta 0:00:03\n",
      "   ------------------------- -------------- 1.3/2.1 MB 277.3 kB/s eta 0:00:03\n",
      "   ------------------------- -------------- 1.3/2.1 MB 277.3 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 1.6/2.1 MB 285.3 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 1.6/2.1 MB 285.3 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 1.6/2.1 MB 285.3 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 1.6/2.1 MB 285.3 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 1.8/2.1 MB 290.1 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.8/2.1 MB 290.1 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.8/2.1 MB 290.1 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.8/2.1 MB 290.1 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 285.8 kB/s eta 0:00:00\n",
      "Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
      "Downloading PyYAML-6.0.2-cp310-cp310-win_amd64.whl (161 kB)\n",
      "Downloading greenlet-3.0.3-cp310-cp310-win_amd64.whl (292 kB)\n",
      "Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: PyYAML, Mako, greenlet, colorlog, sqlalchemy, alembic, optuna\n",
      "Successfully installed Mako-1.3.5 PyYAML-6.0.2 alembic-1.13.2 colorlog-6.8.2 greenlet-3.0.3 optuna-4.0.0 sqlalchemy-2.0.32\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script mako-render.exe is installed in 'c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script alembic.exe is installed in 'c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script optuna.exe is installed in 'c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "%pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 595, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1881, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1344\\3847652366.py\", line 4, in <module>\n",
      "    import torch\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\__init__.py\", line 2120, in <module>\n",
      "    from torch._higher_order_ops import cond\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_higher_order_ops\\__init__.py\", line 1, in <module>\n",
      "    from .cond import cond\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_higher_order_ops\\cond.py\", line 5, in <module>\n",
      "    import torch._subclasses.functional_tensor\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_subclasses\\functional_tensor.py\", line 42, in <module>\n",
      "    class FunctionalTensor(torch.Tensor):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_subclasses\\functional_tensor.py\", line 258, in FunctionalTensor\n",
      "    cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_subclasses\\functional_tensor.py:258: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchsummary import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, jaccard_score\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the paths to train and test datasets\n",
    "TRAIN_DIR = './global-wheat-detection/train/'\n",
    "TEST_DIR = './global-wheat-detection/test/'\n",
    "TRAIN_CSV_PATH = './global-wheat-detection/train.csv'\n",
    "AUG_SAVE_DIR = './global-wheat-detection/augmented_images/'\n",
    "SAVE_PATH = 'models/DBN/'\n",
    "CHECKPOINT_DIR = 'models/DBN/checkpoints/'\n",
    "\n",
    "# Model configuration\n",
    "EPOCHS = 10\n",
    "IMG_SIZE = 28\n",
    "VISIBLE_UNITS = IMG_SIZE * IMG_SIZE\n",
    "HIDDEN_UNITS_1 = 256  # Number of hidden units in the first RBM\n",
    "HIDDEN_UNITS_2 = 128  # Number of hidden units in the second RBM\n",
    "N_CLASSES = 2\n",
    "BATCH_SIZE = 64  # Batch size for training\n",
    "LEARNING_RATE = 0.01  # Learning rate for both pre-training and fine-tuning\n",
    "\n",
    "# Create directories if they don't exist\n",
    "if not os.path.exists(SAVE_PATH):\n",
    "    os.makedirs(SAVE_PATH)\n",
    "if not os.path.exists(CHECKPOINT_DIR):\n",
    "    os.makedirs(CHECKPOINT_DIR)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 242466 entries, 0 to 242465\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count   Dtype  \n",
      "---  ------    --------------   -----  \n",
      " 0   image_id  242466 non-null  object \n",
      " 1   x         242466 non-null  float64\n",
      " 2   y         242466 non-null  float64\n",
      " 3   w         242466 non-null  float64\n",
      " 4   h         242466 non-null  float64\n",
      " 5   source    242466 non-null  object \n",
      "dtypes: float64(4), object(2)\n",
      "memory usage: 11.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./df_augment.csv')\n",
    "# df = pd.read_csv('./df_full.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                image_id                                             bboxes  \\\n",
      "0              00333207f  [[0.0, 654.0, 37.0, 111.0], [0.0, 817.0, 135.0...   \n",
      "1  00333207f_augmented_1  [[0.0, 259.0, 37.25467, 111.0], [0.0, 109.0, 1...   \n",
      "2              005b0d8bb  [[765.0, 879.0, 116.0, 79.0], [84.0, 539.0, 15...   \n",
      "3  005b0d8bb_augmented_1  [[0.0, 0.0, 24.0, 151.0], [260.0, 389.0, 138.0...   \n",
      "4              006a994f7  [[437.0, 988.0, 98.0, 36.0], [309.0, 527.0, 11...   \n",
      "\n",
      "      source  \n",
      "0  arvalis_1  \n",
      "1  arvalis_1  \n",
      "2    usask_1  \n",
      "3    usask_1  \n",
      "4    inrae_1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1344\\3198158563.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_grouped = df.groupby('image_id').apply(lambda group: pd.Series({\n"
     ]
    }
   ],
   "source": [
    "def group_bounding_boxes(group):\n",
    "    bboxes = np.array(list(zip(group['x'], group['y'], group['w'], group['h'])), dtype=np.float32)\n",
    "    return bboxes\n",
    "\n",
    "# Apply the function to group bounding boxes by image_id\n",
    "df_grouped = df.groupby('image_id').apply(lambda group: pd.Series({\n",
    "    'bboxes': group_bounding_boxes(group),\n",
    "    'source': group['source'].iloc[0]  # Keep the source or other necessary columns\n",
    "})).reset_index()\n",
    "\n",
    "# Check the resulting DataFrame\n",
    "print(df_grouped.head())  # This should show 'image_id', 'bboxes', and 'source'\n",
    "\n",
    "# Split the grouped data into training, validation, and test sets\n",
    "train_df, test_df = train_test_split(df_grouped, test_size=0.4, random_state=42)\n",
    "test_df, val_df = train_test_split(test_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Extract image paths\n",
    "train_paths = [os.path.join(TRAIN_DIR, f'{image_id}.jpg') for image_id in train_df['image_id']]\n",
    "val_paths = [os.path.join(TRAIN_DIR, f'{image_id}.jpg') for image_id in val_df['image_id']]\n",
    "test_paths = [os.path.join(TRAIN_DIR, f'{image_id}.jpg') for image_id in test_df['image_id']]\n",
    "\n",
    "# Extract bounding boxes\n",
    "train_bboxes = train_df['bboxes'].tolist()\n",
    "val_bboxes = val_df['bboxes'].tolist()\n",
    "test_bboxes = test_df['bboxes'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of bounding boxes in dataset: 116\n",
      "Images batch shape: torch.Size([64, 3, 28, 28]), Labels batch shape: torch.Size([64, 2, 4]), BBoxes batch shape: torch.Size([64, 118, 4])\n",
      "torch.Size([64, 3, 28, 28]) torch.Size([64, 120, 4]) 22\n",
      "torch.Size([64, 3, 28, 28]) torch.Size([64, 120, 4]) 22\n"
     ]
    }
   ],
   "source": [
    "def load_image_and_bbox(image_id, bboxes, IMG_SIZE=IMG_SIZE):\n",
    "    # Check if the image ID is for an augmented image\n",
    "    if '_augmented_' in image_id:\n",
    "        image_path = f'./global-wheat-detection/augmented_images/{image_id}.jpg'\n",
    "    else:\n",
    "        image_path = f'./global-wheat-detection/train/{image_id}.jpg'\n",
    "\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Warning: File not found: {image_id}. Skipping this file.\")\n",
    "        return None, None\n",
    "\n",
    "    # Load and process the image as before\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    original_size = image.size  # Original size (width, height)\n",
    "    image = image.resize((IMG_SIZE, IMG_SIZE))  # Resize the image to the desired size\n",
    "    image = np.array(image, dtype=np.float32) / 255.0  # Normalize the image to [0, 1] range\n",
    "\n",
    "    # Adjust bounding boxes according to the new image size\n",
    "    scale_w = IMG_SIZE / original_size[0]\n",
    "    scale_h = IMG_SIZE / original_size[1]\n",
    "    bboxes[:, [0, 2]] *= scale_w  # Scale x and w\n",
    "    bboxes[:, [1, 3]] *= scale_h  # Scale y and h\n",
    "\n",
    "    return torch.tensor(image, dtype=torch.float32).permute(2, 0, 1), torch.tensor(bboxes, dtype=torch.float32)\n",
    "\n",
    "def create_dataset(image_paths, bboxes, max_num_boxes):\n",
    "    images = []\n",
    "    targets = []\n",
    "\n",
    "    for img_path, bbox in zip(image_paths, bboxes):\n",
    "        image, bbox_tensor = load_image_and_bbox(img_path, bbox)\n",
    "\n",
    "        if image is None or bbox_tensor is None:\n",
    "            continue  # Skip if the file was not found or an error occurred\n",
    "\n",
    "        # Pad bbox_tensor to max_num_boxes\n",
    "        padded_bbox = torch.zeros((max_num_boxes, 4), dtype=torch.float32)\n",
    "        padded_bbox[:bbox_tensor.size(0), :] = bbox_tensor\n",
    "\n",
    "        images.append(image)\n",
    "        targets.append(padded_bbox)\n",
    "\n",
    "    # Ensure we have non-empty lists before stacking\n",
    "    if len(images) == 0 or len(targets) == 0:\n",
    "        raise ValueError(\"No images or targets were loaded. Check the paths and filenames.\")\n",
    "\n",
    "    images_tensor = torch.stack(images)\n",
    "    bboxes_tensor = torch.stack(targets)\n",
    "\n",
    "    return TensorDataset(images_tensor, bboxes_tensor)\n",
    "\n",
    "def parse_dataframe(df_grouped):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    bboxes = []\n",
    "\n",
    "    for _, group in df_grouped.iterrows():\n",
    "        image_paths.append(group['image_id'])\n",
    "\n",
    "        # bbox_list is already a NumPy array, no need to parse or evaluate\n",
    "        bbox_list = group['bboxes']\n",
    "\n",
    "        # Example condition: check if any bounding box width is greater than 0\n",
    "        label = 1 if any(bbox[2] > 0 for bbox in bbox_list) else 0  # bbox[2] is the width 'w'\n",
    "        labels.append(label)\n",
    "        \n",
    "        # No need to reconstruct the array, it's already structured as expected\n",
    "        bboxes.append(bbox_list)\n",
    "    \n",
    "    return image_paths, labels, bboxes\n",
    "    \n",
    "def collate_fn(batch):\n",
    "    images, bboxes = zip(*batch)\n",
    "    \n",
    "    # Stack images into a batch tensor\n",
    "    images = torch.stack(images)\n",
    "    \n",
    "    # Find the max number of bounding boxes in the batch\n",
    "    max_num_boxes = max(bbox.shape[0] for bbox in bboxes)\n",
    "    \n",
    "    # Pad the bounding boxes to the max number of boxes\n",
    "    padded_bboxes = []\n",
    "    for bbox in bboxes:\n",
    "        padded_bbox = torch.zeros((max_num_boxes, 4), dtype=torch.float32)\n",
    "        padded_bbox[:bbox.shape[0], :] = bbox\n",
    "        padded_bboxes.append(padded_bbox)\n",
    "    \n",
    "    bboxes_tensor = torch.stack(padded_bboxes)\n",
    "    \n",
    "    return images, bboxes_tensor\n",
    "\n",
    "# Load and preprocess the data\n",
    "image_paths, labels, bboxes = parse_dataframe(df_grouped)\n",
    "\n",
    "# Split the dataset\n",
    "train_paths, test_paths, train_labels, test_labels = train_test_split(image_paths, labels, test_size=0.4, random_state=42)\n",
    "test_paths, val_paths, test_labels, val_labels = train_test_split(test_paths, test_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "# Determine the maximum number of bounding boxes\n",
    "max_num_boxes_in_dataset = max(len(bbox) for bbox in train_bboxes + val_bboxes + test_bboxes)\n",
    "print(f\"Maximum number of bounding boxes in dataset: {max_num_boxes_in_dataset}\")\n",
    "\n",
    "# Create PyTorch Datasets\n",
    "# Now perform train-test split and create datasets\n",
    "train_dataset = create_dataset(train_paths, train_bboxes, max_num_boxes=120)\n",
    "val_dataset = create_dataset(val_paths, val_bboxes, max_num_boxes=120)\n",
    "test_dataset = create_dataset(test_paths, test_bboxes, max_num_boxes=120)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# Inspect the DataLoader\n",
    "for images, targets in train_loader:\n",
    "    labels = targets[:, :N_CLASSES]  # Replace N_CLASSES with the actual number of classes\n",
    "    bboxes = targets[:, N_CLASSES:]  # The rest are bounding boxes\n",
    "\n",
    "    print(f\"Images batch shape: {images.shape}, Labels batch shape: {labels.shape}, BBoxes batch shape: {bboxes.shape}\")\n",
    "    break\n",
    "\n",
    "for images, labels in val_loader:\n",
    "    print(images.shape, labels.shape, len(val_loader))\n",
    "    break\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    print(images.shape, labels.shape, len(test_loader))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "    epochs = range(1, len(history['loss']) + 1)\n",
    "\n",
    "    # Plot loss\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, history['loss'], 'r-', label='Training Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, history['accuracy'], 'b-', label='Training Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision Metric\n",
    "def precision_metric(y_true, y_pred):\n",
    "    return precision_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "# Recall Metric\n",
    "def recall_metric(y_true, y_pred):\n",
    "    return recall_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "# F1 Score Metric\n",
    "def f1_metric(y_true, y_pred):\n",
    "    return f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "# Intersection over Union (IoU) Metric\n",
    "def iou_metric(y_true, y_pred):\n",
    "    return jaccard_score(y_true, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM(nn.Module):\n",
    "    def __init__(self, visible_units, hidden_units, k=1):\n",
    "        super(RBM, self).__init__()\n",
    "        self.visible_units = visible_units  # This should match the input size (e.g., 2352 for 28x28x3 images)\n",
    "        self.hidden_units = hidden_units  # Number of hidden units (e.g., 256)\n",
    "        self.k = k  # Number of Gibbs sampling steps\n",
    "\n",
    "        # Initialize weights and biases with correct dimensions\n",
    "        self.W = nn.Parameter(torch.randn(hidden_units, visible_units) * 0.01)\n",
    "        self.h_bias = nn.Parameter(torch.zeros(hidden_units))  # Hidden bias\n",
    "        self.v_bias = nn.Parameter(torch.zeros(visible_units))  # Visible bias\n",
    "\n",
    "    def sample_h(self, v):\n",
    "        # Compute probability of hidden unit given visible units\n",
    "        h_prob = torch.sigmoid(F.linear(v, self.W, self.h_bias))\n",
    "        return h_prob, torch.bernoulli(h_prob)\n",
    "\n",
    "    def sample_v(self, h):\n",
    "        # Compute probability of visible unit given hidden units\n",
    "        v_prob = torch.sigmoid(F.linear(h, self.W.t(), self.v_bias))\n",
    "        return v_prob, torch.bernoulli(v_prob)\n",
    "\n",
    "    def forward(self, v):\n",
    "        # Perform k steps of Gibbs sampling\n",
    "        h_prob, h_sample = self.sample_h(v)\n",
    "        for _ in range(self.k):\n",
    "            v_prob, v_sample = self.sample_v(h_sample)\n",
    "            h_prob, h_sample = self.sample_h(v_sample)\n",
    "        return v_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DBN(nn.Module):\n",
    "    def __init__(self, rbm_layers, n_classes):\n",
    "        super(DBN, self).__init__()\n",
    "        self.rbm_layers = nn.ModuleList(rbm_layers)\n",
    "        self.n_classes = n_classes\n",
    "        self.classifier = nn.Linear(rbm_layers[-1].hidden_units, n_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Pass through each RBM layer\n",
    "        for rbm in self.rbm_layers:\n",
    "            x, _ = rbm.sample_h(x)  # Get the hidden layer output\n",
    "        # Pass through the final classifier layer\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBN_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBNModel(\n",
      "  (rbm1): RBM()\n",
      "  (rbm2): RBM()\n",
      "  (fc_class): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (fc_bbox): Linear(in_features=128, out_features=40, bias=True)\n",
      "  (criterion_class): CrossEntropyLoss()\n",
      "  (criterion_bbox): SmoothL1Loss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class DBNModel(nn.Module):\n",
    "    def __init__(self, visible_units, hidden_units_1, hidden_units_2, n_classes, num_boxes=10):\n",
    "        super(DBNModel, self).__init__()\n",
    "        self.rbm1 = RBM(visible_units, hidden_units_1)\n",
    "        self.rbm2 = RBM(hidden_units_1, hidden_units_2)\n",
    "        \n",
    "        self.fc_class = nn.Linear(in_features=hidden_units_2, out_features=n_classes, bias=True)\n",
    "        self.fc_bbox = nn.Linear(in_features=hidden_units_2, out_features=num_boxes * 4, bias=True)\n",
    "        \n",
    "        self.criterion_class = nn.CrossEntropyLoss()\n",
    "        self.criterion_bbox = nn.SmoothL1Loss()\n",
    "\n",
    "        self.num_boxes = num_boxes  # Store the number of bounding boxes\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flatten input if it's an image\n",
    "        batch_size = x.size(0)\n",
    "        x = x.view(batch_size, -1)  # Flatten to [batch_size, visible_units]\n",
    "\n",
    "        x = self.rbm1(x)\n",
    "        x = self.rbm2(x)\n",
    "        \n",
    "        class_output = self.fc_class(x)\n",
    "        bbox_output = self.fc_bbox(x)\n",
    "        \n",
    "        bbox_output = bbox_output.view(-1, self.num_boxes, 4)\n",
    "        \n",
    "        return class_output, bbox_output\n",
    "\n",
    "    def compile_model(self, learning_rate=0.01):\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "        self.criterion_class = nn.CrossEntropyLoss()  # For class labels\n",
    "        self.criterion_bbox = nn.SmoothL1Loss()  # For bounding boxes\n",
    "\n",
    "    def train_model(self, train_loader, epochs=10, checkpoint_dir=None):\n",
    "        history = {'loss': [], 'accuracy': []}\n",
    "        best_loss = float('inf')\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            self.train()\n",
    "            total_loss = 0\n",
    "            correct = 0\n",
    "            for data, target in train_loader:\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                # Split target into labels and bounding boxes\n",
    "                labels = target[:, 0].long()  # Ensure labels is 1D\n",
    "\n",
    "                # Forward pass through the model\n",
    "                class_output, bbox_output = self.forward(data)\n",
    "\n",
    "                # Get batch size from bbox_output\n",
    "                batch_size = bbox_output.size(0)  # Should be 64\n",
    "\n",
    "                # Calculate the actual number of bounding boxes from the model\n",
    "                num_boxes = self.num_boxes  # Use the num_boxes set in the model\n",
    "\n",
    "                # Ensure `bboxes` has the correct shape\n",
    "                bboxes = target[:, 1:].reshape(batch_size, num_boxes, 4)\n",
    "\n",
    "                # Print shapes for debugging\n",
    "                print(\"bbox_output shape:\", bbox_output.shape)\n",
    "                print(\"bboxes shape:\", bboxes.shape)\n",
    "\n",
    "                # Compute losses\n",
    "                loss_class = self.criterion_class(class_output, labels)\n",
    "                loss_bbox = self.criterion_bbox(bbox_output, bboxes)\n",
    "                total_loss = loss_class + loss_bbox\n",
    "\n",
    "                # Backward pass and optimization\n",
    "                total_loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                total_loss += total_loss.item()\n",
    "                pred = class_output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "\n",
    "            avg_loss = total_loss / len(train_loader)\n",
    "            accuracy = correct / len(train_loader.dataset)\n",
    "            history['loss'].append(avg_loss)\n",
    "            history['accuracy'].append(accuracy)\n",
    "            print(f'Epoch {epoch + 1}/{epochs}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "            # Save checkpoint if this is the best model so far\n",
    "            if checkpoint_dir and avg_loss < best_loss:\n",
    "                best_loss = avg_loss\n",
    "                checkpoint_path = os.path.join(checkpoint_dir, f'epoch_{epoch + 1}_loss_{avg_loss:.4f}.pth')\n",
    "                torch.save(self.state_dict(), checkpoint_path)\n",
    "                print(f\"Checkpoint saved: {checkpoint_path}\")\n",
    "\n",
    "        return history\n",
    "\n",
    "    def evaluate(self, test_loader):\n",
    "        self.eval()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                labels = target[:, 0].long()  # The first element is the class label\n",
    "                bboxes = target[:, 1:].view(-1, 4)  # The rest are bounding boxes\n",
    "\n",
    "                class_output, bbox_output = self.forward(data)\n",
    "                loss_class = self.criterion_class(class_output, labels)\n",
    "                loss_bbox = self.criterion_bbox(bbox_output, bboxes)\n",
    "                total_loss += (loss_class + loss_bbox).item()\n",
    "                pred = class_output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "\n",
    "                y_true.extend(labels.cpu().numpy())\n",
    "                y_pred.extend(pred.cpu().numpy())\n",
    "\n",
    "        avg_loss = total_loss / len(test_loader)\n",
    "        accuracy = correct / len(test_loader.dataset)\n",
    "\n",
    "        print(f'Test Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "        return {\n",
    "            'loss': avg_loss,\n",
    "            'accuracy': accuracy,\n",
    "            'y_true': y_true,\n",
    "            'y_pred': y_pred,\n",
    "        }\n",
    "\n",
    "# Initialize the DBN model with the correct parameters\n",
    "visible_units = 28 * 28 * 3  # For a 28x28 image with 3 channels (RGB)\n",
    "hidden_units_1 = 256\n",
    "hidden_units_2 = 128\n",
    "\n",
    "dbn_model = DBNModel(visible_units=visible_units, hidden_units_1=hidden_units_1, hidden_units_2=hidden_units_2, n_classes=2, num_boxes=10)\n",
    "\n",
    "# Compile the model\n",
    "LEARNING_RATE = 0.01\n",
    "dbn_model.compile_model(learning_rate=LEARNING_RATE)\n",
    "\n",
    "# Print model summary (not as straightforward in PyTorch, but showing the structure)\n",
    "print(dbn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (64x2352 and 256x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mdbn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCHECKPOINT_DIR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Evaluate the DBN model on the test set\u001b[39;00m\n\u001b[0;32m      4\u001b[0m test_metrics \u001b[38;5;241m=\u001b[39m dbn_model\u001b[38;5;241m.\u001b[39mevaluate(test_loader)\n",
      "Cell \u001b[1;32mIn[62], line 50\u001b[0m, in \u001b[0;36mDBNModel.train_model\u001b[1;34m(self, train_loader, epochs, checkpoint_dir)\u001b[0m\n\u001b[0;32m     47\u001b[0m labels \u001b[38;5;241m=\u001b[39m target[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mlong()  \u001b[38;5;66;03m# Ensure labels is 1D\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Forward pass through the model\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m class_output, bbox_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Get batch size from bbox_output\u001b[39;00m\n\u001b[0;32m     53\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m bbox_output\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Should be 64\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[62], line 21\u001b[0m, in \u001b[0;36mDBNModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     18\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Flatten to [batch_size, visible_units]\u001b[39;00m\n\u001b[0;32m     20\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrbm1(x)\n\u001b[1;32m---> 21\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrbm2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m class_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_class(x)\n\u001b[0;32m     24\u001b[0m bbox_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_bbox(x)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[61], line 25\u001b[0m, in \u001b[0;36mRBM.forward\u001b[1;34m(self, v)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, v):\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m# Perform k steps of Gibbs sampling\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m     h_prob, h_sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_h\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk):\n\u001b[0;32m     27\u001b[0m         v_prob, v_sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_v(h_sample)\n",
      "Cell \u001b[1;32mIn[61], line 15\u001b[0m, in \u001b[0;36mRBM.sample_h\u001b[1;34m(self, v)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample_h\u001b[39m(\u001b[38;5;28mself\u001b[39m, v):\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# Compute probability of hidden unit given visible units\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     h_prob \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mh_bias\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m h_prob, torch\u001b[38;5;241m.\u001b[39mbernoulli(h_prob)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x2352 and 256x128)"
     ]
    }
   ],
   "source": [
    "history = dbn_model.train_model(train_loader, epochs=EPOCHS, checkpoint_dir=CHECKPOINT_DIR)\n",
    "\n",
    "# Evaluate the DBN model on the test set\n",
    "test_metrics = dbn_model.evaluate(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training metrics\n",
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire DBN model\n",
    "dbn_model.save(SAVE_PATH + 'dbn_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6755"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the DBN model from a file\n",
    "# dbn_model.load(SAVE_PATH + 'dbn_model.pth')\n",
    "\n",
    "# Perform garbage collection\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBN_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hidden units in the RBM layers are increased to 512 and 256, respectively, which makes this model potentially more capable of capturing complex features but at the cost of increased computational requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the DBN model with more hidden units\n",
    "dbn_model_2 = DBNModel(visible_units=VISIBLE_UNITS, \n",
    "                       hidden_units_1=512,  # Increased from 256 to 512\n",
    "                       hidden_units_2=256,  # Increased from 128 to 256\n",
    "                       n_classes=N_CLASSES)\n",
    "\n",
    "# Compile the model\n",
    "dbn_model_2.compile_model(learning_rate=LEARNING_RATE)\n",
    "\n",
    "# Print model summary\n",
    "print(dbn_model_2.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history_2 = dbn_model_2.train(train_loader, epochs=EPOCHS, checkpoint_dir=CHECKPOINT_DIR)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_metrics_2 = dbn_model_2.evaluate(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training metrics\n",
    "plot_metrics(history_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "dbn_model_2.save(SAVE_PATH + 'dbn_model_2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model (if needed)\n",
    "# dbn_model_2.load(SAVE_PATH + 'dbn_model_2.pth')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBN_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A third RBM layer with 64 hidden units is added, making the network deeper. This modification allows the DBN to potentially learn even more abstract features but also requires careful tuning and more data to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the DBN model with an additional RBM layer\n",
    "class DBNModelExtended(DBNModel):\n",
    "    def build_model(self):\n",
    "        # Initialize RBMs with an additional layer\n",
    "        rbm1 = RBM(visible_units=self.visible_units, hidden_units=self.hidden_units_1)\n",
    "        rbm2 = RBM(visible_units=self.hidden_units_1, hidden_units=self.hidden_units_2)\n",
    "        rbm3 = RBM(visible_units=self.hidden_units_2, hidden_units=64)  # New additional RBM layer\n",
    "        \n",
    "        # Stack RBMs to form a DBN\n",
    "        dbn = DBN(rbm_layers=[rbm1, rbm2, rbm3], n_classes=self.n_classes)\n",
    "        return dbn\n",
    "\n",
    "# Initialize the DBN model\n",
    "dbn_model_3 = DBNModelExtended(visible_units=VISIBLE_UNITS, \n",
    "                               hidden_units_1=HIDDEN_UNITS_1, \n",
    "                               hidden_units_2=HIDDEN_UNITS_2, \n",
    "                               n_classes=N_CLASSES)\n",
    "\n",
    "# Compile the model\n",
    "dbn_model_3.compile_model(learning_rate=LEARNING_RATE)\n",
    "\n",
    "# Print model summary\n",
    "print(dbn_model_3.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history_3 = dbn_model_3.train(train_loader, epochs=EPOCHS, checkpoint_dir=CHECKPOINT_DIR)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_metrics_3 = dbn_model_3.evaluate(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training metrics\n",
    "plot_metrics(history_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "dbn_model_3.save(SAVE_PATH + 'dbn_model_3.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model (if needed)\n",
    "# dbn_model_3.load(SAVE_PATH + 'dbn_model_3.pth')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving History"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[I just did for first DBN model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the training history for the first DBN model\n",
    "with open('dbn_training_history_1.pkl', 'wb') as file:\n",
    "    pickle.dump(history, file)\n",
    "\n",
    "# Save the training history for the second DBN model\n",
    "#with open('dbn_training_history_2.pkl', 'wb') as file:\n",
    "#    pickle.dump(history_2, file)\n",
    "\n",
    "# Save the training history for the third DBN model\n",
    "#with open('dbn_training_history_3.pkl', 'wb') as file:\n",
    "#    pickle.dump(history_3, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Module.train() got an unexpected keyword argument 'epochs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m dbn_model\u001b[38;5;241m.\u001b[39mcompile_model(learning_rate\u001b[38;5;241m=\u001b[39mLEARNING_RATE)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Train the model for zero epochs to create an empty history object\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m empty_history_1 \u001b[38;5;241m=\u001b[39m \u001b[43mdbn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Set the loaded history to the empty history object\u001b[39;00m\n\u001b[0;32m     18\u001b[0m empty_history_1 \u001b[38;5;241m=\u001b[39m loaded_history_1\n",
      "\u001b[1;31mTypeError\u001b[0m: Module.train() got an unexpected keyword argument 'epochs'"
     ]
    }
   ],
   "source": [
    "# Load the training history for the first DBN model\n",
    "with open('dbn_training_history_1.pkl', 'rb') as file:\n",
    "    loaded_history_1 = pickle.load(file)\n",
    "\n",
    "# Initialize the model again if needed\n",
    "dbn_model = DBNModel(visible_units=VISIBLE_UNITS, \n",
    "                     hidden_units_1=HIDDEN_UNITS_1, \n",
    "                     hidden_units_2=HIDDEN_UNITS_2, \n",
    "                     n_classes=N_CLASSES)\n",
    "\n",
    "# Compile the model\n",
    "dbn_model.compile_model(learning_rate=LEARNING_RATE)\n",
    "\n",
    "# Train the model for zero epochs to create an empty history object\n",
    "empty_history_1 = dbn_model.train(train_loader, epochs=0, checkpoint_dir=None)\n",
    "\n",
    "# Set the loaded history to the empty history object\n",
    "empty_history_1 = loaded_history_1\n",
    "\n",
    "# Now empty_history_1 contains the loaded history\n",
    "plot_metrics(empty_history_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning (For DBN_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-03 09:39:20,229] A new study created in memory with name: no-name-9ea89b7b-d5af-43d5-bef8-a6e727dba4b8\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from optuna import Trial\n",
    "\n",
    "class DBNHyperModel:\n",
    "    def __init__(self, visible_units, n_classes):\n",
    "        self.visible_units = visible_units\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "    def build(self, trial: Trial):\n",
    "        # Sample hyperparameters\n",
    "        hidden_units_1 = trial.suggest_int('hidden_units_1', 128, 512, step=64)\n",
    "        hidden_units_2 = trial.suggest_int('hidden_units_2', 64, 256, step=64)\n",
    "        learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
    "\n",
    "        # Build the DBN\n",
    "        rbm1 = RBM(visible_units=self.visible_units, hidden_units=hidden_units_1)\n",
    "        rbm2 = RBM(visible_units=hidden_units_1, hidden_units=hidden_units_2)\n",
    "\n",
    "        dbn = DBN(rbm_layers=[rbm1, rbm2], n_classes=self.n_classes)\n",
    "        optimizer = optim.Adam(dbn.parameters(), lr=learning_rate)\n",
    "        \n",
    "        return dbn, optimizer\n",
    "\n",
    "    def objective(self, trial: Trial):\n",
    "        # Build the model\n",
    "        model, optimizer = self.build(trial)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Train the model\n",
    "        model.train()\n",
    "        for epoch in range(EPOCHS):\n",
    "            total_loss = 0\n",
    "            for data, target in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for data, target in val_loader:\n",
    "                    output = model(data)\n",
    "                    loss = criterion(output, target)\n",
    "                    val_loss += loss.item()\n",
    "            val_loss /= len(val_loader)\n",
    "\n",
    "            # Report intermediate objective value\n",
    "            trial.report(val_loss, epoch)\n",
    "\n",
    "            # Handle pruning (optional)\n",
    "            if trial.should_prune():\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "        return val_loss\n",
    "\n",
    "# Initialize the hypermodel\n",
    "hypermodel = DBNHyperModel(visible_units=VISIBLE_UNITS, n_classes=N_CLASSES)\n",
    "\n",
    "# Create an Optuna study\n",
    "study = optuna.create_study(direction='minimize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-03 09:50:05,013] A new study created in memory with name: no-name-723a551e-3a67-4a60-8ea9-aaa868aca995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.0689, Accuracy: 0.9876\n",
      "Epoch 2/10, Loss: 0.0065, Accuracy: 0.9996\n",
      "Epoch 3/10, Loss: 0.0039, Accuracy: 0.9996\n",
      "Epoch 4/10, Loss: 0.0035, Accuracy: 0.9996\n",
      "Epoch 5/10, Loss: 0.0035, Accuracy: 0.9996\n",
      "Epoch 6/10, Loss: 0.0035, Accuracy: 0.9996\n",
      "Epoch 7/10, Loss: 0.0035, Accuracy: 0.9996\n",
      "Epoch 8/10, Loss: 0.0035, Accuracy: 0.9996\n",
      "Epoch 9/10, Loss: 0.0035, Accuracy: 0.9996\n",
      "Epoch 10/10, Loss: 0.0035, Accuracy: 0.9996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-09-03 09:51:31,064] Trial 0 finished with value: 0.9996700622757455 and parameters: {'learning_rate': 9.878972647192918e-05, 'hidden_units_1': 253, 'hidden_units_2': 42}. Best is trial 0 with value: 0.9996700622757455.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0029, Accuracy: 0.9997, Precision: 0.9993, Recall: 0.9997, F1-Score: 0.9995, IoU: 0.9993\n",
      "Epoch 1/10, Loss: 0.0041, Accuracy: 0.9996\n",
      "Epoch 2/10, Loss: 0.0037, Accuracy: 0.9996\n",
      "Epoch 3/10, Loss: 0.0037, Accuracy: 0.9996\n",
      "Epoch 4/10, Loss: 0.0037, Accuracy: 0.9996\n",
      "Epoch 5/10, Loss: 0.0038, Accuracy: 0.9996\n",
      "Epoch 6/10, Loss: 0.0038, Accuracy: 0.9996\n",
      "Epoch 7/10, Loss: 0.0040, Accuracy: 0.9996\n",
      "Epoch 8/10, Loss: 0.0037, Accuracy: 0.9996\n",
      "Epoch 9/10, Loss: 0.0037, Accuracy: 0.9996\n",
      "Epoch 10/10, Loss: 0.0036, Accuracy: 0.9996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-09-03 09:53:20,823] Trial 1 finished with value: 0.9996700622757455 and parameters: {'learning_rate': 0.003917501016697021, 'hidden_units_1': 253, 'hidden_units_2': 112}. Best is trial 0 with value: 0.9996700622757455.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0030, Accuracy: 0.9997, Precision: 0.9993, Recall: 0.9997, F1-Score: 0.9995, IoU: 0.9993\n",
      "Epoch 1/10, Loss: 0.0045, Accuracy: 0.9996\n",
      "Epoch 2/10, Loss: 0.0035, Accuracy: 0.9996\n",
      "Epoch 3/10, Loss: 0.0035, Accuracy: 0.9996\n",
      "Epoch 4/10, Loss: 0.0034, Accuracy: 0.9996\n",
      "Epoch 5/10, Loss: 0.0032, Accuracy: 0.9996\n",
      "Epoch 6/10, Loss: 0.0032, Accuracy: 0.9996\n",
      "Epoch 7/10, Loss: 0.0031, Accuracy: 0.9996\n",
      "Epoch 8/10, Loss: 0.0032, Accuracy: 0.9996\n",
      "Epoch 9/10, Loss: 0.0031, Accuracy: 0.9996\n",
      "Epoch 10/10, Loss: 0.0031, Accuracy: 0.9996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-09-03 09:54:56,543] Trial 2 finished with value: 0.9996700622757455 and parameters: {'learning_rate': 0.0006517151787620411, 'hidden_units_1': 180, 'hidden_units_2': 122}. Best is trial 0 with value: 0.9996700622757455.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0026, Accuracy: 0.9997, Precision: 0.9993, Recall: 0.9997, F1-Score: 0.9995, IoU: 0.9993\n",
      "Epoch 1/10, Loss: 0.0116, Accuracy: 0.9974\n",
      "Epoch 2/10, Loss: 0.0035, Accuracy: 0.9996\n",
      "Epoch 3/10, Loss: 0.0035, Accuracy: 0.9996\n",
      "Epoch 4/10, Loss: 0.0035, Accuracy: 0.9996\n",
      "Epoch 5/10, Loss: 0.0035, Accuracy: 0.9996\n",
      "Epoch 6/10, Loss: 0.0034, Accuracy: 0.9996\n",
      "Epoch 7/10, Loss: 0.0033, Accuracy: 0.9996\n",
      "Epoch 8/10, Loss: 0.0032, Accuracy: 0.9996\n",
      "Epoch 9/10, Loss: 0.0031, Accuracy: 0.9996\n",
      "Epoch 10/10, Loss: 0.0031, Accuracy: 0.9996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-09-03 09:56:25,054] Trial 3 finished with value: 0.9996700622757455 and parameters: {'learning_rate': 0.00021508185937587108, 'hidden_units_1': 212, 'hidden_units_2': 127}. Best is trial 0 with value: 0.9996700622757455.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0026, Accuracy: 0.9997, Precision: 0.9993, Recall: 0.9997, F1-Score: 0.9995, IoU: 0.9993\n",
      "Epoch 1/10, Loss: 0.0047, Accuracy: 0.9996\n",
      "Epoch 2/10, Loss: 0.0035, Accuracy: 0.9996\n",
      "Epoch 3/10, Loss: 0.0035, Accuracy: 0.9996\n",
      "Epoch 4/10, Loss: 0.0035, Accuracy: 0.9996\n",
      "Epoch 5/10, Loss: 0.0033, Accuracy: 0.9996\n",
      "Epoch 6/10, Loss: 0.0033, Accuracy: 0.9996\n",
      "Epoch 7/10, Loss: 0.0032, Accuracy: 0.9996\n",
      "Epoch 8/10, Loss: 0.0032, Accuracy: 0.9996\n",
      "Epoch 9/10, Loss: 0.0031, Accuracy: 0.9996\n",
      "Epoch 10/10, Loss: 0.0030, Accuracy: 0.9996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-09-03 09:57:35,934] Trial 4 finished with value: 0.9996700622757455 and parameters: {'learning_rate': 0.0008040224411322317, 'hidden_units_1': 193, 'hidden_units_2': 110}. Best is trial 0 with value: 0.9996700622757455.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0025, Accuracy: 0.9997, Precision: 0.9993, Recall: 0.9997, F1-Score: 0.9995, IoU: 0.9993\n",
      "Epoch 1/10, Loss: 0.0054, Accuracy: 0.9992\n",
      "Epoch 2/10, Loss: 0.0061, Accuracy: 0.9996\n",
      "Epoch 3/10, Loss: 0.0072, Accuracy: 0.9996\n",
      "Epoch 4/10, Loss: 0.0066, Accuracy: 0.9996\n",
      "Epoch 5/10, Loss: 0.0064, Accuracy: 0.9996\n",
      "Epoch 6/10, Loss: 0.0068, Accuracy: 0.9996\n",
      "Epoch 7/10, Loss: 0.0075, Accuracy: 0.9996\n",
      "Epoch 8/10, Loss: 0.0069, Accuracy: 0.9996\n",
      "Epoch 9/10, Loss: 0.0066, Accuracy: 0.9996\n",
      "Epoch 10/10, Loss: 0.0068, Accuracy: 0.9996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-09-03 09:59:11,375] Trial 5 finished with value: 0.9996700622757455 and parameters: {'learning_rate': 0.06174435285619339, 'hidden_units_1': 161, 'hidden_units_2': 67}. Best is trial 0 with value: 0.9996700622757455.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0046, Accuracy: 0.9997, Precision: 0.9993, Recall: 0.9997, F1-Score: 0.9995, IoU: 0.9993\n",
      "Epoch 1/10, Loss: 0.0041, Accuracy: 0.9996\n",
      "Epoch 2/10, Loss: 0.0039, Accuracy: 0.9996\n",
      "Epoch 3/10, Loss: 0.0039, Accuracy: 0.9996\n",
      "Epoch 4/10, Loss: 0.0039, Accuracy: 0.9996\n",
      "Epoch 5/10, Loss: 0.0039, Accuracy: 0.9996\n",
      "Epoch 6/10, Loss: 0.0039, Accuracy: 0.9996\n",
      "Epoch 7/10, Loss: 0.0038, Accuracy: 0.9996\n",
      "Epoch 8/10, Loss: 0.0040, Accuracy: 0.9996\n",
      "Epoch 9/10, Loss: 0.0038, Accuracy: 0.9996\n",
      "Epoch 10/10, Loss: 0.0036, Accuracy: 0.9996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-09-03 09:59:53,601] Trial 6 finished with value: 0.9996700622757455 and parameters: {'learning_rate': 0.007210993240990051, 'hidden_units_1': 64, 'hidden_units_2': 113}. Best is trial 0 with value: 0.9996700622757455.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0031, Accuracy: 0.9997, Precision: 0.9993, Recall: 0.9997, F1-Score: 0.9995, IoU: 0.9993\n",
      "Epoch 1/10, Loss: 0.0123, Accuracy: 0.9996\n",
      "Epoch 2/10, Loss: 0.0252, Accuracy: 0.9996\n",
      "Epoch 3/10, Loss: 0.0254, Accuracy: 0.9996\n",
      "Epoch 4/10, Loss: 0.0196, Accuracy: 0.9996\n",
      "Epoch 5/10, Loss: 0.0310, Accuracy: 0.9996\n",
      "Epoch 6/10, Loss: 0.0171, Accuracy: 0.9996\n",
      "Epoch 7/10, Loss: 0.0204, Accuracy: 0.9996\n",
      "Epoch 8/10, Loss: 0.0224, Accuracy: 0.9996\n",
      "Epoch 9/10, Loss: 0.0225, Accuracy: 0.9996\n",
      "Epoch 10/10, Loss: 0.0390, Accuracy: 0.9992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-09-03 10:00:58,628] Trial 7 finished with value: 0.9996700622757455 and parameters: {'learning_rate': 0.0805728504542829, 'hidden_units_1': 79, 'hidden_units_2': 118}. Best is trial 0 with value: 0.9996700622757455.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0030, Accuracy: 0.9997, Precision: 0.9993, Recall: 0.9997, F1-Score: 0.9995, IoU: 0.9993\n",
      "Epoch 1/10, Loss: 0.0043, Accuracy: 0.9996\n",
      "Epoch 2/10, Loss: 0.0036, Accuracy: 0.9996\n",
      "Epoch 3/10, Loss: 0.0036, Accuracy: 0.9996\n",
      "Epoch 4/10, Loss: 0.0036, Accuracy: 0.9996\n",
      "Epoch 5/10, Loss: 0.0036, Accuracy: 0.9996\n",
      "Epoch 6/10, Loss: 0.0035, Accuracy: 0.9996\n",
      "Epoch 7/10, Loss: 0.0035, Accuracy: 0.9996\n",
      "Epoch 8/10, Loss: 0.0034, Accuracy: 0.9996\n",
      "Epoch 9/10, Loss: 0.0034, Accuracy: 0.9996\n",
      "Epoch 10/10, Loss: 0.0035, Accuracy: 0.9996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-09-03 10:01:54,177] Trial 8 finished with value: 0.9996700622757455 and parameters: {'learning_rate': 0.0023371786016238784, 'hidden_units_1': 71, 'hidden_units_2': 56}. Best is trial 0 with value: 0.9996700622757455.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0027, Accuracy: 0.9997, Precision: 0.9993, Recall: 0.9997, F1-Score: 0.9995, IoU: 0.9993\n",
      "Epoch 1/10, Loss: 0.0040, Accuracy: 0.9996\n",
      "Epoch 2/10, Loss: 0.0038, Accuracy: 0.9996\n",
      "Epoch 3/10, Loss: 0.0037, Accuracy: 0.9996\n",
      "Epoch 4/10, Loss: 0.0039, Accuracy: 0.9996\n",
      "Epoch 5/10, Loss: 0.0038, Accuracy: 0.9996\n",
      "Epoch 6/10, Loss: 0.0039, Accuracy: 0.9996\n",
      "Epoch 7/10, Loss: 0.0038, Accuracy: 0.9996\n",
      "Epoch 8/10, Loss: 0.0039, Accuracy: 0.9996\n",
      "Epoch 9/10, Loss: 0.0039, Accuracy: 0.9996\n",
      "Epoch 10/10, Loss: 0.0036, Accuracy: 0.9996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-09-03 10:03:14,765] Trial 9 finished with value: 0.9996700622757455 and parameters: {'learning_rate': 0.005260938656803787, 'hidden_units_1': 173, 'hidden_units_2': 109}. Best is trial 0 with value: 0.9996700622757455.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0031, Accuracy: 0.9997, Precision: 0.9993, Recall: 0.9997, F1-Score: 0.9995, IoU: 0.9993\n",
      "Epoch 1/10, Loss: 0.1034, Accuracy: 0.9996\n",
      "Epoch 2/10, Loss: 0.0165, Accuracy: 0.9996\n",
      "Epoch 3/10, Loss: 0.0070, Accuracy: 0.9996\n",
      "Epoch 4/10, Loss: 0.0044, Accuracy: 0.9996\n",
      "Epoch 5/10, Loss: 0.0037, Accuracy: 0.9996\n",
      "Epoch 6/10, Loss: 0.0035, Accuracy: 0.9996\n",
      "Epoch 7/10, Loss: 0.0035, Accuracy: 0.9996\n",
      "Epoch 8/10, Loss: 0.0035, Accuracy: 0.9996\n",
      "Epoch 9/10, Loss: 0.0035, Accuracy: 0.9996\n",
      "Epoch 10/10, Loss: 0.0035, Accuracy: 0.9996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-09-03 10:04:13,647] Trial 10 finished with value: 0.9996700622757455 and parameters: {'learning_rate': 2.3309743071295687e-05, 'hidden_units_1': 121, 'hidden_units_2': 34}. Best is trial 0 with value: 0.9996700622757455.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0030, Accuracy: 0.9997, Precision: 0.9993, Recall: 0.9997, F1-Score: 0.9995, IoU: 0.9993\n",
      "Epoch 1/10, Loss: 0.0393, Accuracy: 0.9996\n",
      "Epoch 2/10, Loss: 0.0048, Accuracy: 0.9996\n",
      "Epoch 3/10, Loss: 0.0036, Accuracy: 0.9996\n",
      "Epoch 4/10, Loss: 0.0035, Accuracy: 0.9996\n",
      "Epoch 5/10, Loss: 0.0035, Accuracy: 0.9996\n",
      "Epoch 6/10, Loss: 0.0035, Accuracy: 0.9996\n",
      "Epoch 7/10, Loss: 0.0035, Accuracy: 0.9996\n",
      "Epoch 8/10, Loss: 0.0035, Accuracy: 0.9996\n",
      "Epoch 9/10, Loss: 0.0035, Accuracy: 0.9996\n",
      "Epoch 10/10, Loss: 0.0034, Accuracy: 0.9996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-09-03 10:05:51,695] Trial 11 finished with value: 0.9996700622757455 and parameters: {'learning_rate': 3.63166235297209e-05, 'hidden_units_1': 255, 'hidden_units_2': 89}. Best is trial 0 with value: 0.9996700622757455.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0030, Accuracy: 0.9997, Precision: 0.9993, Recall: 0.9997, F1-Score: 0.9995, IoU: 0.9993\n",
      "Epoch 1/10, Loss: 0.0246, Accuracy: 0.9928\n",
      "Epoch 2/10, Loss: 0.0036, Accuracy: 0.9996\n",
      "Epoch 3/10, Loss: 0.0035, Accuracy: 0.9996\n",
      "Epoch 4/10, Loss: 0.0035, Accuracy: 0.9996\n",
      "Epoch 5/10, Loss: 0.0035, Accuracy: 0.9996\n",
      "Epoch 6/10, Loss: 0.0035, Accuracy: 0.9996\n",
      "Epoch 7/10, Loss: 0.0034, Accuracy: 0.9996\n",
      "Epoch 8/10, Loss: 0.0033, Accuracy: 0.9996\n",
      "Epoch 9/10, Loss: 0.0032, Accuracy: 0.9996\n",
      "Epoch 10/10, Loss: 0.0032, Accuracy: 0.9996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-09-03 10:07:25,498] Trial 12 finished with value: 0.9996700622757455 and parameters: {'learning_rate': 0.0001619532166098359, 'hidden_units_1': 244, 'hidden_units_2': 90}. Best is trial 0 with value: 0.9996700622757455.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0027, Accuracy: 0.9997, Precision: 0.9993, Recall: 0.9997, F1-Score: 0.9995, IoU: 0.9993\n",
      "Epoch 1/10, Loss: 0.0422, Accuracy: 0.9996\n",
      "Epoch 2/10, Loss: 0.0056, Accuracy: 0.9996\n",
      "Epoch 3/10, Loss: 0.0038, Accuracy: 0.9996\n",
      "Epoch 4/10, Loss: 0.0035, Accuracy: 0.9996\n",
      "Epoch 5/10, Loss: 0.0035, Accuracy: 0.9996\n",
      "Epoch 6/10, Loss: 0.0035, Accuracy: 0.9996\n",
      "Epoch 7/10, Loss: 0.0035, Accuracy: 0.9996\n",
      "Epoch 8/10, Loss: 0.0035, Accuracy: 0.9996\n",
      "Epoch 9/10, Loss: 0.0035, Accuracy: 0.9996\n",
      "Epoch 10/10, Loss: 0.0035, Accuracy: 0.9996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-09-03 10:09:07,124] Trial 13 finished with value: 0.9996700622757455 and parameters: {'learning_rate': 9.622734519115696e-05, 'hidden_units_1': 217, 'hidden_units_2': 34}. Best is trial 0 with value: 0.9996700622757455.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0029, Accuracy: 0.9997, Precision: 0.9993, Recall: 0.9997, F1-Score: 0.9995, IoU: 0.9993\n",
      "Epoch 1/10, Loss: 0.1598, Accuracy: 0.9996\n",
      "Epoch 2/10, Loss: 0.0289, Accuracy: 0.9996\n",
      "Epoch 3/10, Loss: 0.0129, Accuracy: 0.9996\n",
      "Epoch 4/10, Loss: 0.0069, Accuracy: 0.9996\n",
      "Epoch 5/10, Loss: 0.0047, Accuracy: 0.9996\n",
      "Epoch 6/10, Loss: 0.0039, Accuracy: 0.9996\n",
      "Epoch 7/10, Loss: 0.0036, Accuracy: 0.9996\n",
      "Epoch 8/10, Loss: 0.0035, Accuracy: 0.9996\n",
      "Epoch 9/10, Loss: 0.0035, Accuracy: 0.9996\n",
      "Epoch 10/10, Loss: 0.0035, Accuracy: 0.9996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-09-03 10:10:27,636] Trial 14 finished with value: 0.9996700622757455 and parameters: {'learning_rate': 1.102208317347008e-05, 'hidden_units_1': 232, 'hidden_units_2': 55}. Best is trial 0 with value: 0.9996700622757455.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0030, Accuracy: 0.9997, Precision: 0.9993, Recall: 0.9997, F1-Score: 0.9995, IoU: 0.9993\n",
      "Epoch 1/10, Loss: 0.0043, Accuracy: 0.9992\n",
      "Epoch 2/10, Loss: 0.0041, Accuracy: 0.9996\n",
      "Epoch 3/10, Loss: 0.0043, Accuracy: 0.9996\n",
      "Epoch 4/10, Loss: 0.0043, Accuracy: 0.9996\n",
      "Epoch 5/10, Loss: 0.0043, Accuracy: 0.9996\n",
      "Epoch 6/10, Loss: 0.0043, Accuracy: 0.9996\n",
      "Epoch 7/10, Loss: 0.0044, Accuracy: 0.9996\n",
      "Epoch 8/10, Loss: 0.0043, Accuracy: 0.9996\n",
      "Epoch 9/10, Loss: 0.0044, Accuracy: 0.9996\n",
      "Epoch 10/10, Loss: 0.0043, Accuracy: 0.9996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-09-03 10:11:54,521] Trial 15 finished with value: 0.9996700622757455 and parameters: {'learning_rate': 0.013622459919849759, 'hidden_units_1': 138, 'hidden_units_2': 98}. Best is trial 0 with value: 0.9996700622757455.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0036, Accuracy: 0.9997, Precision: 0.9993, Recall: 0.9997, F1-Score: 0.9995, IoU: 0.9993\n",
      "Epoch 1/10, Loss: 0.0083, Accuracy: 0.9996\n",
      "Epoch 2/10, Loss: 0.0035, Accuracy: 0.9996\n",
      "Epoch 3/10, Loss: 0.0035, Accuracy: 0.9996\n",
      "Epoch 4/10, Loss: 0.0035, Accuracy: 0.9996\n",
      "Epoch 5/10, Loss: 0.0035, Accuracy: 0.9996\n",
      "Epoch 6/10, Loss: 0.0033, Accuracy: 0.9996\n",
      "Epoch 7/10, Loss: 0.0032, Accuracy: 0.9996\n",
      "Epoch 8/10, Loss: 0.0032, Accuracy: 0.9996\n",
      "Epoch 9/10, Loss: 0.0031, Accuracy: 0.9996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-09-03 10:13:23,049] Trial 16 failed with parameters: {'learning_rate': 0.0004452590697871375, 'hidden_units_1': 209, 'hidden_units_2': 73} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29868\\2676700373.py\", line 13, in objective\n",
      "    history_1 = model.train_model(train_loader, epochs=EPOCHS)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29868\\2904860317.py\", line 61, in train_model\n",
      "    self.optimizer.step()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\optimizer.py\", line 89, in _use_grad\n",
      "    ret = func(self, *args, **kwargs)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\adam.py\", line 226, in step\n",
      "    adam(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\optimizer.py\", line 161, in maybe_fallback\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\adam.py\", line 766, in adam\n",
      "    func(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\adam.py\", line 431, in _single_tensor_adam\n",
      "    denom = (exp_avg_sq.sqrt() / bias_correction2_sqrt).add_(eps)\n",
      "KeyboardInterrupt\n",
      "[W 2024-09-03 10:13:23,049] Trial 16 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Run the optimization\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Retrieve the best hyperparameters\u001b[39;00m\n\u001b[0;32m     28\u001b[0m best_hyperparameters \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_trial\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[42], line 13\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile_model(learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Train the model (you may use your existing train_loader and val_loader)\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m history_1 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the validation set\u001b[39;00m\n\u001b[0;32m     16\u001b[0m val_metrics \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(val_loader)\n",
      "Cell \u001b[1;32mIn[41], line 61\u001b[0m, in \u001b[0;36mDBNModel.train_model\u001b[1;34m(self, train_loader, epochs, checkpoint_dir)\u001b[0m\n\u001b[0;32m     59\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(output, target)\n\u001b[0;32m     60\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 61\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     64\u001b[0m pred \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\optimizer.py:484\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    479\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    480\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    481\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    482\u001b[0m             )\n\u001b[1;32m--> 484\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\optimizer.py:89\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     88\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 89\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     91\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\adam.py:226\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    214\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    216\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    217\u001b[0m         group,\n\u001b[0;32m    218\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    223\u001b[0m         state_steps,\n\u001b[0;32m    224\u001b[0m     )\n\u001b[1;32m--> 226\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\optimizer.py:161\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\adam.py:766\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    764\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 766\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    767\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    768\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    769\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    775\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    777\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\adam.py:431\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    429\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    430\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 431\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    433\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[0;32m    435\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the objective function\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters for tuning\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-1, log=True)\n",
    "    hidden_units_1 = trial.suggest_int('hidden_units_1', 64, 256)\n",
    "    hidden_units_2 = trial.suggest_int('hidden_units_2', 32, 128)\n",
    "\n",
    "    # Create the model with the suggested hyperparameters\n",
    "    model = DBNModel(visible_units=784, hidden_units_1=hidden_units_1, hidden_units_2=hidden_units_2, n_classes=2)\n",
    "    model.compile_model(learning_rate=learning_rate)\n",
    "\n",
    "    # Train the model (you may use your existing train_loader and val_loader)\n",
    "    history_1 = model.train_model(train_loader, epochs=EPOCHS)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    val_metrics = model.evaluate(val_loader)\n",
    "\n",
    "    # The objective is to maximize accuracy, so return the validation accuracy\n",
    "    return val_metrics['accuracy']\n",
    "\n",
    "# Create a study object\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# Run the optimization\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Retrieve the best hyperparameters\n",
    "best_hyperparameters = study.best_trial\n",
    "\n",
    "# Extract the best learning rate if it was tuned\n",
    "best_learning_rate = best_hyperparameters.params.get('learning_rate', 0.001)  # Default to 0.001 if not tuned\n",
    "\n",
    "# Print the best learning rate to verify\n",
    "print(f\"Best learning rate: {best_learning_rate}\")\n",
    "print(best_hyperparameters.params)\n",
    "\n",
    "# Build the model using the best hyperparameters\n",
    "best_model, best_optimizer = hypermodel.build(best_hyperparameters)\n",
    "\n",
    "# Ensure the optimizer uses the best learning rate\n",
    "for param_group in best_optimizer.param_groups:\n",
    "    param_group['lr'] = best_learning_rate\n",
    "\n",
    "# Example of a learning rate scheduler and early stopping in PyTorch\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = ReduceLROnPlateau(best_optimizer, mode='min', factor=0.2, patience=3, min_lr=1e-5)\n",
    "\n",
    "# Early stopping parameters\n",
    "early_stopping_patience = 5\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "history_best = {'loss': [], 'val_loss': [], 'accuracy': [], 'val_accuracy': []}\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    best_model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    # Training loop\n",
    "    for data, target in train_loader:\n",
    "        best_optimizer.zero_grad()\n",
    "        output = best_model(data)\n",
    "        loss = nn.CrossEntropyLoss()(output, target)\n",
    "        loss.backward()\n",
    "        best_optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    # Validation loop\n",
    "    best_model.eval()\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            output = best_model(data)\n",
    "            loss = nn.CrossEntropyLoss()(output, target)\n",
    "            val_loss += loss.item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            val_correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    # Compute average losses\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    train_accuracy = correct / len(train_loader.dataset)\n",
    "    val_accuracy = val_correct / len(val_loader.dataset)\n",
    "    \n",
    "    # Append to history\n",
    "    history_best['loss'].append(avg_train_loss)\n",
    "    history_best['val_loss'].append(avg_val_loss)\n",
    "    history_best['accuracy'].append(train_accuracy)\n",
    "    history_best['val_accuracy'].append(val_accuracy)\n",
    "    \n",
    "    # Print epoch summary\n",
    "    print(f'Epoch {epoch+1}/{EPOCHS}, Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Accuracy: {train_accuracy:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
    "    \n",
    "    # Early stopping and learning rate scheduling\n",
    "    scheduler.step(avg_val_loss)\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(best_model.state_dict(), os.path.join(CHECKPOINT_DIR, 'best_dbn_model.pth'))  # Save the best model\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    if patience_counter >= early_stopping_patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "# Load the best model\n",
    "best_model.load_state_dict(torch.load(os.path.join(CHECKPOINT_DIR, 'best_dbn_model.pth')))\n",
    "best_model.eval()\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        output = best_model(data)\n",
    "        loss = nn.CrossEntropyLoss()(output, target)\n",
    "        test_loss += loss.item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "test_accuracy = correct / len(test_loader.dataset)\n",
    "\n",
    "print(f'Best model testing Loss: {test_loss:.4f}, Testing Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "torch.save(best_model.state_dict(), SAVE_PATH + 'best_dbn_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
